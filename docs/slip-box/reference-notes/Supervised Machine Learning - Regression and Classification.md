# Week 1: Introduction to Machine Learning

## Supervised Learning
- The most common types of algorithms being used today
	- learns from 'input' to 'output label'
	- use cases: spam filtering, speech recognition, machine translation, online advertising, self driving
- Gives the algorithm datasets to learn from labelled "correct answers"
	- *Regression modeling* is to predict a range of numbers
	- *Classification modeling* is to predict a limited set of class/category
## Unsupervised Learning
- Learns from unlabelled output data to find patterns or interesting properties
	- learns from 'input' only as there are no 'output label'
- Anomaly detection
- Clustering
- Dimensionality reduction

## [[Linear Regression Model]]
- Fitting a *straight line* to a dataset
	- produce a function that produces a y-hat (estimated y) 
	- formulated as a `wx+b` since it is a linear function
	- to train/adjust the unknown parameters/coefficients/weights of the function we need to construct a cost function
- Cost function is a way to quantitatively evaluate the goodness of fit of the function
	- $J(w, b) = rmse/mse$
	- Can be minimized with [[gradient descent]] to find the optimal parameters

# Week 2: Regression with multiple input variables


# Week 3 

#machine-learning #course