<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-slip-box/reference-notes/Hands On Machine Learning">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Hands On Machine Learning | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://your-docusaurus-test-site.com/docs/slip-box/reference-notes/Hands On Machine Learning"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Hands On Machine Learning | My Site"><meta data-rh="true" name="description" content="- Metadata"><meta data-rh="true" property="og:description" content="- Metadata"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-test-site.com/docs/slip-box/reference-notes/Hands On Machine Learning"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/docs/slip-box/reference-notes/Hands On Machine Learning" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/docs/slip-box/reference-notes/Hands On Machine Learning" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.99c6e2a1.css">
<link rel="preload" href="/assets/js/runtime~main.e81c3511.js" as="script">
<link rel="preload" href="/assets/js/main.11de2009.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">My Site</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Second Brain</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Second Brain Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/3 ways to regret ff">3 ways to regret ff</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/IG account of super obvious charts">IG account of super obvious charts</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/code/bash-snippets">code</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/daily-notes/2020/2020-04-07">daily-notes</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/roam/Roam Life ðŸ—º">roam</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/slip-box/ðŸ“¬ Slip Box Index">slip-box</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/ðŸ“¬ Slip Box Index">ðŸ“¬ Slip Box Index</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/slip-box/literature-notes/Anomoly Detection">literature-notes</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/slip-box/permanent-notes/1a entry to creativity">permanent-notes</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/slip-box/reference-notes/10 Papers Every Developer Should Read">reference-notes</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/10 Papers Every Developer Should Read">10 Papers Every Developer Should Read</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/538 NBA Prediction Methodology">538 NBA Prediction Methodology</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/A Counterfactual Framework for Seller-Side AB Testing on Marketplaces">A Counterfactual Framework for Seller-Side AB Testing on Marketplaces</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/A Psalm for the Wild-Built">A Psalm for the Wild-Built</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Aggregation Theory">Aggregation Theory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/American Gods">American Gods</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/An experimental evaluation of the assumption of independence in multiversion programming">An experimental evaluation of the assumption of independence in multiversion programming</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Anthroprocene Reviewed">Anthroprocene Reviewed</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Antifragile">Antifragile</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Arguments and results">Arguments and results</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Atomic Habits">Atomic Habits</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Bad Blood">Bad Blood</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Bayesian Linear Regression">Bayesian Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Bells Theorem">Bells Theorem</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Beware of K-S Test">Beware of K-S Test</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Big Data Specialization Degree">Big Data Specialization Degree</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Big O Notation">Big O Notation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Bitcoin is battery">Bitcoin is battery</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Bitcoin is not battery">Bitcoin is not battery</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Bitcoin is time">Bitcoin is time</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Black Swan">Black Swan</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Blayney Meadow Trail">Blayney Meadow Trail</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Book Club - Federalist Papers">Book Club - Federalist Papers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Building EV infrastructure to grow the EV market">Building EV infrastructure to grow the EV market</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Buying vs Renting">Buying vs Renting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Camping Notes">Camping Notes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Cars and Second Order Consequences">Cars and Second Order Consequences</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/ChatGPT to help me program an app">ChatGPT to help me program an app</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Cognitive Bias">Cognitive Bias</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Commentary on scientific evidence">Commentary on scientific evidence</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Comparison between Gravity and Destination Choice Models">Comparison between Gravity and Destination Choice Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Daily Stoic">Daily Stoic</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Data Science Cheat Sheet">Data Science Cheat Sheet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Data Science Learning">Data Science Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Deep Learning Specialization">Deep Learning Specialization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Desolation Wilderness Hike">Desolation Wilderness Hike</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Dune">Dune</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/EMME tips and tricks">EMME tips and tricks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Eight Factors of Productivity">Eight Factors of Productivity</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/ElasticNet">ElasticNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Elo ratings">Elo ratings</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Exhalation">Exhalation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Fantasy Football">Fantasy Football</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Fast Fourier Transform">Fast Fourier Transform</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Feynman Technique">Feynman Technique</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/First Rule of Machine Learning - Start without Machine Learning">First Rule of Machine Learning - Start without Machine Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Five Ways to Ensure Models Serve Society - A Manifesto">Five Ways to Ensure Models Serve Society - A Manifesto</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Franklin 299">Franklin 299</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Functional Data Engineering">Functional Data Engineering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Gaussian Mixture Models">Gaussian Mixture Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Get Started with Roam">Get Started with Roam</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Good Coding Practice">Good Coding Practice</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Google 43 rules of machine learning">Google 43 rules of machine learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Greenlight">Greenlight</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/HTTP Response Codes">HTTP Response Codes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/slip-box/reference-notes/Hands On Machine Learning">Hands On Machine Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Hike the West Coast Trail">Hike the West Coast Trail</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How does GPT work">How does GPT work</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How to Become a Data Engineer">How to Become a Data Engineer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How to Take Smart Notes - 10 Principles to Revolutionize Your Note-Taking and Writing">How to Take Smart Notes - 10 Principles to Revolutionize Your Note-Taking and Writing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How to be more tech-savvy like the amish">How to be more tech-savvy like the amish</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How to master any skill">How to master any skill</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How to take Smart Notes">How to take Smart Notes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/How to write better">How to write better</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Hurdle Model">Hurdle Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/I want to die but I want to eat tteokbokki">I want to die but I want to eat tteokbokki</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/If">If</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Imaginary Numbers">Imaginary Numbers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Inadequate Equilibrium">Inadequate Equilibrium</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Inflation">Inflation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Inside of a Dog - What Dogs See, Smell, and Know">Inside of a Dog - What Dogs See, Smell, and Know</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Interesting Words">Interesting Words</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Intro to OOP">Intro to OOP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Introduction to Apache Airflow">Introduction to Apache Airflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Introduction to Big Data">Introduction to Big Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Inverted yield curve">Inverted yield curve</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Jeff Nippard Workout">Jeff Nippard Workout</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/John Muir Trail">John Muir Trail</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Kalman Filters">Kalman Filters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Keras">Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Kernel Regression">Kernel Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Klara and the Sun">Klara and the Sun</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Lasso Regression">Lasso Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Learn About Investing">Learn About Investing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Linear regression model">Linear regression model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/MLOps">MLOps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Machine Learning Specialization">Machine Learning Specialization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Many Glaciers Backcountry Hike">Many Glaciers Backcountry Hike</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Master Plan Part III">Master Plan Part III</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Modelling Transport">Modelling Transport</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Moores Law for Everything">Moores Law for Everything</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Movie poster characteristics and pie charts">Movie poster characteristics and pie charts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Mt Whitney">Mt Whitney</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Need Data Engineers not Data Scientists">Need Data Engineers not Data Scientists</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Numbers">Numbers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Perfect Puppy in 7 Days">Perfect Puppy in 7 Days</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Polynomial regression model">Polynomial regression model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Practical SQL for Data Analysis">ðŸ“° Summary (use your own words)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Primer on casual inference">Primer on casual inference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Project Hail Mary">Project Hail Mary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Pythagorean expectation">Pythagorean expectation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Quadratic Programming">Quadratic Programming</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Random Podcast Notes">Random Podcast Notes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Regularization Techniques">Regularization Techniques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Relocation to SF Information">Relocation to SF Information</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Responsibility">Responsibility</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Revolutionary battery checklist">Revolutionary battery checklist</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Ridge Regression">Ridge Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Roam Research">Roam Research</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/SF Homeless Problem">SF Homeless Problem</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/SHAP">SHAP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/SQL Crash Course">SQL Crash Course</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Science is a strong-link problem">Science is a strong-link problem</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Scikit-Learn">Scikit-Learn</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Slow Living">Slow Living</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Software 2.0">Software 2.0</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Some thoughts on machine learning with small data">Some thoughts on machine learning with small data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Speed is the killer feature">Speed is the killer feature</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Strong Opinions, Weakly Held">Strong Opinions, Weakly Held</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Studying Studies">Studying Studies</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Support Vector Machines">Support Vector Machines</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/TensorFlow">TensorFlow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Bank Effect">The Bank Effect</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Four Agreements">The Four Agreements</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Impact of COVID-19 on Residential Relocation Decisions in GTA">The Impact of COVID-19 on Residential Relocation Decisions in GTA</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Overstory">The Overstory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Paper Menagerie">The Paper Menagerie</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Paradox of Our Time">The Paradox of Our Time</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Puppy Primer">The Puppy Primer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Sun Was Dimmer">The Sun Was Dimmer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Tail End">The Tail End</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The Wave">The Wave</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/The real reason fans hate the last season of game of thrones">The real reason fans hate the last season of game of thrones</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Thousand Island Lake">Metadata</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Til2022">Til2022</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Til2023">Til2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Tobit Model">Tobit Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Travel Demand Model Presentation">Travel Demand Model Presentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Trivia Braindump">Trivia Braindump</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/UBI">UBI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Unpredictability">Unpredictability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/VanLife">VanLife</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/We Are Legion (We are Bob)">We Are Legion (We are Bob)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Web 3 Impressions">Web 3 Impressions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/West Coast Trial">West Coast Trial</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/What data cannot do">What data cannot do</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/What is our problem">What is our problem</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Why OKRs are not effective in practice">Why OKRs are not effective in practice</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Why We Sleep">Why We Sleep</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Why are tech stocks falling">Why are tech stocks falling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Why t-test dont work with large samples">Why t-test dont work with large samples</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Winning Fixes Everything">Winning Fixes Everything</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Work Interview Prep">Work Interview Prep</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Working From Bed Is Actually Great">Working From Bed Is Actually Great</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/X-Learner">X-Learner</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Yosemite">Yosemite</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Zen of Zettelkasten">Zen of Zettelkasten</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Zettelkasten Method">Zettelkasten Method</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/Zillow Machine Learning Team">Zillow Machine Learning Team</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/aaronson-oracle-baseball">aaronson-oracle-baseball</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/blue-bus-red-bus">blue-bus-red-bus</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/fast-ai">fast-ai</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/flow state">flow state</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/golang">golang</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/gradient descent">gradient descent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/growth mindset">growth mindset</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/inferring-purpose-of-ride-hailing">inferring-purpose-of-ride-hailing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/k-fold cross validation">k-fold cross validation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/learning curves">learning curves</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/log-likelihood">log-likelihood</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/meta-cognition">meta-cognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/normal equation">normal equation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/practical-statistics">practical-statistics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/python-logging">python-logging</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/slip-box/reference-notes/tyranny of convenience">tyranny of convenience</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/slip-box/writing-bin/Making Sense of the Data Science Stack">writing-bin</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/templates/Article Summary Template">templates</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/â—¶ Trackers">â—¶ Trackers</a></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">slip-box</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">reference-notes</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Hands On Machine Learning</span><meta itemprop="position" content="3"></li></ul></nav><div class="theme-doc-markdown markdown"><header><h1>Hands On Machine Learning</h1></header><ul><li>Metadata<ul><li>Source: <a href="https://github.com/ageron/handson-ml" target="_blank" rel="noopener noreferrer">https://github.com/ageron/handson-ml</a></li><li>#learning #machine-learning #data-science </li></ul></li></ul><h1>Preface</h1><ul><li>The wave of machine learning is started in 2006 when Geoffrey Hinton published a paper on the practicality of training a deep neural network with &quot;Deep Learning&quot;</li><li>Will learn to use [<!-- -->[Scikit-Learn]<!-- -->], [<!-- -->[TensorFlow]<!-- -->], [<!-- -->[Keras]<!-- -->]</li><li>Roadmap of the book<ul><li>Part I - The Fundamentals of Machine Learning (focused on [<!-- -->[Scikit-Learn]<!-- -->])<ul><li>What ML is</li><li><strong>Steps to a typical ML project</strong></li><li>Cost function and how to optimize it</li><li>Data wrangling</li><li>Feature selection and engineering</li><li>(Hyper)parameter tuning, model selection via cross-validation</li><li>Challenges of ML</li><li>Common/Traditional ML algorithms</li><li>Reducing dimensionality</li><li>Unsupervised ML algorithms</li></ul></li><li>Part II - Neural networks and deep learning (focused on [<!-- -->[TensorFlow]<!-- -->] and [<!-- -->[Keras]<!-- -->])<ul><li>What neural nets are</li><li>Build and train NN with [<!-- -->[TensorFlow]<!-- -->] and [<!-- -->[Keras]<!-- -->]</li><li>Important NN architectures </li><li>Techniques for training deep NN</li><li>RL to build a bot</li><li>Loading and preprocessing big data</li><li>Training and deploying [<!-- -->[TensorFlow]<!-- -->] at scale</li></ul></li></ul></li></ul><h1>Chapter 1. The Machine Learning Landscape</h1><ul><li>Machine learning is to improve the ability of doing a certain task with experience, measured by a performance metric</li><li>Main types of ML<ul><li>Whether they are trained under human supervision (supervised vs unsupervised)</li><li>Whether they can learn incrementally on the fly (online vs batch learning)</li><li>Whether they work by comparing data points or detecting patterns in the data (instance based or model based)</li></ul></li><li>The segmentation for human supervision are<ul><li>Supervised learning<ul><li>Training data includes labels, which are the ground truths</li><li>These are good for classification problems (spam vs ham) or regression problems (price of house given a set of features)</li></ul></li><li>Unsupervised learning<ul><li>Training data <strong>does not</strong> have labels</li><li>These are good for detecting patterns like clustering problems (k means) or anomaly detection or dimensionality reduction or association rule learning problems</li><li>Dimensionality reduction is an important technique in ML, that simplify the data without losing information - several features can merge into one because they are related (feature extraction)</li><li>Association rule learning is to learn relationships between attributes from data<ul><li>Supermarket putting two items in the same isle to promote sales</li></ul></li></ul></li><li>Semisupervised learning<ul><li>Labelling all the data is expensive, so you can combine labelled and unlabelled data together to partially labelled data</li></ul></li><li>Reinforcement learning<ul><li>An agent observes the environment and makes an action, which the system rewards or penalizes</li><li>Using this feedback, the agent develops a strategy (policy) to maximize rewards over time</li></ul></li></ul></li><li>Learning from training data can be done all at once or incrementally<ul><li>Batch learning<ul><li>Learn from all the data and use the model in application</li><li>Good when data is not continuous</li></ul></li><li>Online learning<ul><li>Learn data as small batches</li><li>Good when resources are limited and data is constantly streaming in</li><li>Beware of learning from bad data, close monitoring is required. Also optimizing learning rate to carry inertia or react to new data requires thought</li><li>==out-of-core== learning is to artificially break large data sets into small batches and trained with this method</li></ul></li></ul></li><li>How well the model generalize the training into application<ul><li>Instance-based learning<ul><li>Makes predictions by comparing them with examples in the data</li></ul></li><li>Model-based learning<ul><li>Makes predictions with a model</li></ul></li></ul></li><li>Main Challenges of ML<ul><li>Bad data<ul><li>Michele Banko and Eric Brill (Microsoft) published a <a href="https://dl.acm.org/doi/10.3115/1073012.1073017" target="_blank" rel="noopener noreferrer">paper</a> in 2001 that showed that if given enough data the simple models perform just as well as complex ones</li><li>Small datasets have <strong>sampling noise</strong> and <strong>sampling bias</strong><ul><li>An famous example of sampling bias was during the 1936 US election, Literary Digest conduct a very large survey on the voter&#x27;s preference for Landon and Roosevelt<ul><li>The sampling method was flawed because the sampling population was mostly wealthier who favoured Landon (Republican)</li><li>Less than 25% of the original population answered, introducing ==nonresponse bias==</li></ul></li></ul></li><li>Cleaning up training data by removing outliers and incomplete data may help with training</li><li>Using irrelevant features </li></ul></li><li>Bad algorithm<ul><li>Overfitting on training data and coming to a general conclusion that is not true about the population</li><li>NN will be able to detect subtle relationships in data, but any noise or bias may cause it to capture these relationships incorrectly</li><li>Under-fitting on training data will also lead to false conclusions about the population</li></ul></li></ul></li><li>Testing and validation<ul><li>Using a test sample to evaluate the performance of the algorithm by looking at the generalized or out-of-sample error rate<ul><li>If training error is low but out-of-sample error is high, then the model has overfitted the data</li></ul></li><li>It is also common to tune hyperparameters to reduce this out-of-sample error but now you have just adapted the model to the testing data<ul><li>==So it is common to have another hold-out set for validation==</li><li>However, since there may not be enough data to do all three tasks - a technique called &quot;cross-validation&quot; is used to shuffle training/test/validation sets so the hyperparameters can be tuned and then the final set of hyperparameters is used on the training set and validated on the validation set</li></ul></li><li>#til2021 No Free Lunch Theorem<ul><li>David Wolpert in a famous paper (1996) showed that if you make no assumptions about the data, there is no reason to choose one model over another</li><li>There is no way to know ahead of time that one model will work better than another</li><li>Thus, to practically build models you have to make some assumptions</li></ul></li></ul></li></ul><h1>Chapter 2: End to End Machine Learning Project</h1><ul><li>To measure the performance of a model common metrics are RMSE and MAE, <strong>which measures the distance between prediction and actual</strong><ul><li>Root mean squared error (RMSE)<ul><li>$$\sqrt{\frac{1}{m} \sum{\hat{y} - y}}$$</li><li>Standard metric, but is prone to outliers</li></ul></li><li>Mean absolute error (MAE)<ul><li>$$\frac{1}{m}\sum{|\hat{y} - y|}$$</li></ul></li></ul></li><li>Data preparation: Splitting training, test and validation set is critical to not overtrain the model<ul><li>Naively splitting doesn&#x27;t work because every time you split you may end up with different splits and that doesn&#x27;t give reproducible results and the algorithm will see the entire dataset if it is continuously trained</li><li>Sampling bias might be introduced if the distribution of the respondents is not representative of the general population, so <strong>stratified sampling</strong> is used to overcome this</li></ul></li><li>Data exploration: correlation coefficients, matrix<ul><li><code>corr()</code> simply calculates the <strong>linear correlation</strong> between various features</li><li>Ranges from -1 and 1 which denotes negative correlation and positive correlation</li><li>A value close to 0 means no linear correlation, ==which doesn&#x27;t rule out other correlations==</li><li><img loading="lazy" src="https://en.wikipedia.org/wiki/File:Correlation_examples2.svg" alt="pearson&#x27;s correlation figure" class="img_ev3q"></li><li><strong>The goal here is to identify data quirks to remove/clean before feeding into the training</strong></li></ul></li><li>Feature engineering: cleaning, transforming, combining attributes<ul><li>Feature cleaning involves removing empty values from the dataset<ul><li>There are three options for missing features: remove the data entry, remove the feature, or set values to median, mean or zero</li><li><strong>It is important to do this only for the training set</strong><ul><li>For mean/median calculation, they should be computed on the training set but also applied to the test set when testing the accuracy</li></ul></li><li><code>sklearn.impute.SimpleImputer</code> takes care of imputing missing values</li></ul></li><li>Feature generation involves combining features into more useful ones such as normalizing certain features with another to give more context </li><li>Feature transformation involves changing features into different forms that is suitable for ML<ul><li>Convert text categories into numbers<ul><li><code>sklearn.preprocessing.OrdinalEncoder</code> which turns text into ranked list, but ML will assume two close by values are similar</li><li><code>sklearn.preprocessing.OneHotEncoder</code> which turns text in to dummy attributes and doesn&#x27;t imply close by values matter</li></ul></li><li>If one-hot encoding is resulting in a large number of input features and slowing down ML performance, ==you can replace categorical input with useful numerical features==<ul><li>i.e. Country code can be proxied with GDP or population</li><li>i.e. Ocean proximity can actually be distance in meters</li><li>==Or you can replace each category with a learnable low dimensional vector called an embedding==</li></ul></li></ul></li><li>Feature scaling shifts the values in a feature for ML<ul><li><strong>Usually, ML doesn&#x27;t perform well on datasets with features in various scales</strong>. </li><li>Min-max scaling (aka <strong>normalization</strong>) changes values such that it is between two values, most commonly 0 and 1</li><li>Standardization scaling changes the values such that the mean is 0 and distribution has a unit variance</li></ul></li></ul></li><li>[<!-- -->[Scikit-Learn]<!-- -->] - Core API design principles</li><li>Select and Train a Model<ul><li>Linear regression model<ul><li>A good baseline model to compare others too</li><li>Might underfitting the data</li><li>Main ways to fix under-fitting is selecting a more powerful model, to feed the training algorithm with better features, or to reduce the constraints on the model.</li></ul></li><li>Decision Tree Regressor<ul><li>A powerful model that is capable of finding nonlinear relationships in data</li><li>Easy to overfit, so use cross-validation to evaluate the models</li></ul></li><li>Random Forest Regressor<ul><li>Training many decision trees on random subsets of the feature, then averaging out their predictions</li><li>A kind of <strong>ensemble learning</strong> which is building a model on top of many other models</li></ul></li><li>Others to try are Support Vector Machines or even Neural Networks</li><li>At this stage, one should aim to shortlist a few high potential models <ul><li>To save their hyperparameters and trained parameters we can use <code>pickle</code> or <code>joblib</code> from sklearn</li></ul></li></ul></li><li>Fine Tune Your Model<ul><li>Once you have a shortlist of models, we need to fine tune each one though grid search, randomized search, ensemble methods</li><li>Grid Search<ul><li>Programmatically search through all the hyperparameter combinations using <code>GridSerachCV</code></li><li>When you don&#x27;t have a good sense of the grid to search with, a good approach is consecutive powers of 10</li><li>Once the grid search is done, find the best combination of parameters by <code>grid_serach.best_params_</code> and see if they are the upper limit of the grid you setup<ul><li>Try searching again if they are the maximum values in the grid</li></ul></li></ul></li><li>Randomized Search<ul><li>Grid search is a good option when the space is limited, but if the search space is large then we can use <code>RandomizedSearchCV</code> instead</li><li>It can search for more combinations with less cost</li></ul></li><li>Ensemble Methods<ul><li>Combining models that perform the best since a group of model will often perform better than the best individual model</li><li>Analyze the best model by inspecting their feature importance and dropping the ones that is less important</li></ul></li></ul></li><li>Evaluate Final Model on Test Set<ul><li>Prepare the reserved test data set the same way and fit it through the estimator</li><li>Be sure to only <code>transform()</code> and not <code>fit_transform()</code></li><li>Also generalize the error in production with a confidence interval to get a sense of the variations in the error</li><li>Performance will usually be slightly worse on test set than on training set, but not always</li></ul></li><li>Launch, Monitor and Maintain Your Model/System<ul><li>Plugging the production input data into the system and writing tests</li><li>Write monitoring code to check your system&#x27;s live performance at regular intervals and trigger alerts when it drops<ul><li>Models tend to &#x27;rot&#x27; as data evolves over time (or drift)</li></ul></li><li>Evaluating your system&#x27;s performance will require sampling the system&#x27;s prediction and evaluating them</li><li>Evaluate the systems input data quality</li><li>Retrain the model on a regular basis using fresh data</li></ul></li></ul><h1>Chapter 3: Classification</h1><ul><li>MNIST dataset is the &quot;Hello World&quot; of ML, a dataset of handwritten digits</li><li>Scikit-Learn provides this dataset as part of the library <code>fetch_openml(&#x27;mnist_784&#x27;, version=1)</code><ul><li>Datasets from Scikit-Learn generally have a similar dictionary structure that includes <code>DESCR</code> key describing the dataset, <code>data</code> key containing an array with one row per instance and one column per feature, <code>target</code> key containing an array with the labels</li></ul></li><li>Binary Classifier<ul><li>==Able to identify one thing by distinguishing between that thing and not-that-thing==</li><li>Scikit&#x27;s Stochastic Gradient Descent (SGD) classifier is a good place to start<ul><li>It can handle large datasets efficiently</li><li>Also suited for online training because it deals with one instance at a time</li><li>It relies on randomness and shuffled data so it is not suited for any time-series analysts</li></ul></li></ul></li><li>Evaluating Classifiers<ul><li>A trickier subject compared to evaluating regressors</li><li>Cross-validation<ul><li>Similar to how we evaluated the regression model </li><li>But can be problematic on <strong>skewed datasets</strong></li></ul></li><li>Confusion matrix<ul><li>A better way to examine a classifier</li><li><strong>Precision</strong> is the measure of how many true positives were predicted out of all the predicted positives<ul><li>$$Precision = \frac{TP}{TP + FP}$$</li></ul></li><li><strong>Recall</strong> is the measure of how many true positives were predicted out of all the actual positives<ul><li>$$Recall = \frac{TP}{TP + FN}$$</li></ul></li><li><strong>F1 Score</strong> is the combined metric of precision and recall. This will favor model that balances both metrics however that may not always be true</li><li>Precision/Recall Tradeoff<ul><li>When you increase precision, you will decrease recall</li><li>This is because a classifier like SGDClassifier has a decision function that determines the threshold of where to assign the positive and negative instances</li><li>To determine what the ideal threshold for the decision function, we can plot the <strong>precision recall curve</strong></li></ul></li><li>ROC Curve<ul><li>The receiver operating characteristic curve is another way to tune the classifier</li><li>It plots the <code>true-positive rate (recall)</code> against <code>false-positive rate</code><ul><li>False-positive rate is <code>1 - specificity (true-negative rate)</code></li></ul></li><li>Thus, it plots sensitivity (recall) against 1 - specificity</li><li>Usually it is plotted against a diagonal which represents a random classifier and <strong>good classifiers will be as far away from the diagonal as possible</strong></li><li>The area under the curve (AUC) is another metric to quantify the performance, a perfect classifier will have an AUC of 1.0 and random classifier will have an AUC of 0.5</li></ul></li><li>==Use PR curve when positive class is rare and you care about false positives, and ROC curve when negative class is rare==</li></ul></li><li>Error analysis<ul><li>After going through the machine learning checklist you arrive at the fine tuned model, you want to understand what kind of error it is producing</li><li>Use the confusion matrix</li></ul></li></ul></li><li>Multi-class Classifier<ul><li>Distinguishes between many classes</li><li>These can be native multi-class classifiers like RandomForestClassifier or naive Bayes classifier, or multiple binary classifiers can be combined to do this like Support Vector Machine classifier or Vector Classifier</li><li>One-versus-all (OvA) strategy<ul><li>Train n binary classifiers for each of the n classes</li><li>Pick the classifier that gives the highest score</li></ul></li><li>One-versus-one (OvO) strategy<ul><li>Train $$n \times \frac{n-1}{2}$$ binary classifiers for each pair of classes</li><li>The benefit of this strategy is that you only need to train on data with the two classes</li><li>The disadvantage is that it scales non-linearly as the number of classes increases</li></ul></li><li>OvO is preferred with classifiers that are more efficient on smaller datasets (SVM)while OvA is preferred most other binary classifiers<ul><li>Scikit-learn will automatically optimize the strategy for the classifier</li></ul></li></ul></li><li>Multilabel Classifier<ul><li>Provide multiple outputs for an input</li><li>Evaluating this classifier can be measuring F1 score for each individual label then compute the average score</li></ul></li><li>Multioutput Classifier<ul><li>Generalizes the multi-class classification where each label can be multi-class</li><li>A example would be a system that removes noise from images which means it outputs multiple labels with various values for each label</li></ul></li></ul><h1>Chapter 4: Training Models</h1><ul><li>Understanding how the models work under the hood</li><li>[<!-- -->[Linear regression model]<!-- -->]<ul><li>There are two ways to train linear regression models</li><li>A closed-form [<!-- -->[normal equation]<!-- -->] to compute parameters that best fit the model to the training set and <strong>iterative optimization approach [<!-- -->[gradient descent]<!-- -->] that gradually tweaks the parameters to minimize the cost function over the training set</strong></li></ul></li><li>[<!-- -->[Polynomial regression model]<!-- -->]<ul><li>More complex as it can fit non-linear dataset and since it has more parameters than linear regression it is prone to <strong>overfitting</strong> the training set</li><li>To overcome this, we will detect this using [<!-- -->[learning curves]<!-- -->] and reduce the risk of overfitting with [<!-- -->[Regularization Techniques]<!-- -->] </li></ul></li><li>Machine learning model&#x27;s errors can be expressed as the sum of three different errors<ul><li>==Bias==: from wrong assumptions</li><li>==Variance==: from excessive sensitivity to small variations in the data, likely from high degrees of freedom</li><li>==Irreducible errors==: from noise in the data itself, fixed by cleaning</li><li>There is a tradeoff between these three error sources, increasing a model&#x27;s complexity will increase variance and reduce bias and vice versa</li></ul></li><li>Logistic regression model<ul><li>To estimate probability that an instance belongs to a particular class</li><li>Works by computing the weighted sum of the features (+ bias term) and apply the <strong>logistic</strong>  to the result<ul><li>A <strong>sigmoid function</strong> that produces a number between 0 and 1</li><li>$$\sigma(t) = \frac{1}{1+exp(-t)}$$</li><li>logit is the inverse of the logistic</li></ul></li><li>To train a logistic model we have to use gradient descent because there is no close form equation</li><li>Can also be regularized to prevent overfitting</li></ul></li><li>Softmax regression model<ul><li>Also known as <strong>multinomial logistic regression</strong>, which supports multiple classes</li><li>Applies a normalized exponential equation (softmax) to the score of each class<ul><li>The score is computed like a linear regression</li><li>Softmax equation: $$\hat{p}=\frac{exp(s<em>k(x))}{\sum</em>{j=1}^{K}=exp(s_j(x))}$$<ul><li>Where $K$ is the number of classes, $s(x)$ is the vector of the scores for each class, $\hat{p}$ is the estimated probability that the instance $x$ belongs to $k$ </li></ul></li></ul></li></ul></li></ul><h1>Chapter 5: Support Vector Machines</h1><ul><li>SVM is capable of linear and nonlinear classification, regression and outlier detection<ul><li>One of the most popular ML models</li></ul></li><li>Linear SVM Classification<ul><li>Fitting the largest possible gap between two classes with a <strong>straight line</strong></li><li>The <strong>support</strong> comes from the instances located on the edge of this gap<ul><li>Adding more instances outside will not affect the decision boundary</li></ul></li><li>==Very sensitive to scale, so always be sure to feature scale the dataset for linear SVM classification==</li></ul></li><li>Soft Margin Classification<ul><li>A more flexible model that allows for instances that end up in the boundary or on the wrong side</li></ul></li><li>Nonlinear SVM Classification<ul><li>When a dataset is not linearly separable on one feature, you can introduce more features to result in a linearly separable dataset</li><li>There are a few ways to add more features<ul><li>Polynomial Kernel<ul><li>==A way to add many polynomial features without actually adding them so the feature set does not explode==</li></ul></li><li>Adding Similarity Features<ul><li>Measures how much each instance resembles a particular <strong>landmark</strong></li><li>Similarity can be measured with the <strong>Gaussian Radial Bias Function (RBF)</strong></li><li>And when the features are transformed to the similarity values, the instances become linearly separable </li></ul></li></ul></li></ul></li><li>SVM Regression<ul><li>Instead of fitting a gap <strong>between</strong> the instances, you fit the <strong>gap</strong> to cross the most instances</li></ul></li></ul><h1>Chapter 6: Decision Trees</h1><ul><li>Can perform both classification and regression modeling</li><li>Building blocks of Chapter 7: Random Forests </li><li>To make a prediction with decision tree you go through nodes and you move down the tree&#x27;s nodes until you reach the final node that gives the prediction</li><li>Classification and Regression Tree (CART) Algorithm<ul><li>Splits the training set using a single feature <code>k</code> and threshold <code>t_k</code> by searching for the pair that produces the purest set</li><li>It recursively splits the subsets until it reaches the maximize depth</li><li>It is a greedy search </li></ul></li><li>Decision trees are prone to over-fitting because it is <em>nonparametric</em><ul><li>The number of parameters is not determined prior to training</li><li>Needs to be regularized to avoid overfitting</li></ul></li><li>Instabilities with decision tree<ul><li>loves orthogonal decision boundaries, which creates overfitting</li></ul></li></ul><h1>Chapter 7: Ensemble Learning and Random Forests</h1><ul><li>Ensemble learning is equivalent to the &quot;wisdom of the crowd&quot; where you take a group of predictors and their aggregated answer</li><li>An ensemble of decision trees is a random forest<ul><li>Each tree is trained on a subset of data and they are aggregated together to make the prediction</li></ul></li><li><h2 class="anchor anchorWithStickyNavbar_LWe7" id="voting-classifiers">Voting Classifiers<a class="hash-link" href="#voting-classifiers" title="Direct link to heading">â€‹</a></h2><ul><li>The final prediction is made based on the most voted result from the predictors</li><li>Surprisingly can make a strong learner from a group of weak learners</li></ul></li><li>Ensemble methods work best with diversity<ul><li>One way is to diversify the training algorithms, the more varied they are the better</li><li>Another way is to use the same algorithm but train on different subset of data - this is called &quot;bagging&quot;</li></ul></li><li><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bagging-and-pasting">Bagging and Pasting<a class="hash-link" href="#bagging-and-pasting" title="Direct link to heading">â€‹</a></h2><ul><li>Short for &quot;bootstrap aggregating&quot;</li><li>When it is done without replacement then its called pasting</li><li>Out-of-bag instances are the ones sampled by bagging, however there are some instances that will never be sampled which can be used for evaluations</li></ul></li><li><h2 class="anchor anchorWithStickyNavbar_LWe7" id="random-forests">Random Forests<a class="hash-link" href="#random-forests" title="Direct link to heading">â€‹</a></h2><ul><li>Ensemble of decision trees, usually trained via the bagging method</li><li>Has ways to introduce randomness to create more tree diversity</li><li>Feature importance is easily computed with random forests</li></ul></li><li><h2 class="anchor anchorWithStickyNavbar_LWe7" id="boosting">Boosting<a class="hash-link" href="#boosting" title="Direct link to heading">â€‹</a></h2><ul><li>Any ensemble method that combines several weak learners to a strong learner</li><li>General idea is to train predictors sequentially, each trying to correct its predecessor</li><li>AdaBoost<ul><li>Focusing on the training instances that the predecessor under-fitted</li><li>Resulting in new predictors more focused on harder cases</li></ul></li><li>Gradient Boosting<ul><li>Unlike AdaBoost, instead of adjusting the instance weights at every iteration, this method fits to the residual error made by the previous predictor</li></ul></li><li>Stacking<ul><li>Instead of using trivial functions (hard voting) to aggregate the predictions, why don&#x27;t we train a model to perform this aggregation </li><li>There is a final predictor after the layer of predictors called blender (or meta learner) that takes it all to make the last prediction</li></ul></li></ul></li></ul><h1>Chapter 8: Dimensionality Reduction</h1><ul><li>Curse of dimensionality is when the problem has too many features<ul><li>High dimensional datasets are also very sparse</li><li>Which leads to overfitting (a problem we always try to avoid)</li></ul><ul><li><strong>Projection</strong><ul><li>problems in the real-world often don&#x27;t have evenly spaced out features</li><li>most features are static, many are correlated</li><li>this means that features can be reduced to a lower subspace<ul><li><strong>watch out for data in a swiss roll shape that would just be squashed</strong></li></ul></li></ul></li><li><strong>Manifold Learning</strong><ul><li>Something that is d dim but rolled in the d+1 dim</li><li>These algorithms works by learning the manifold on which it lies</li></ul></li><li>Principal component analysis<ul><li>Identifies the hyperplane the data lies on and then projects onto it<ul><li>Does this by picking the axis that minimizes the mean squared distance between the original data and its projection</li><li>And then picks the second axis which is orthogonal </li><li>And so on</li></ul></li><li>Gives explained variance ratio of every principle component</li><li>The number of dimension one decides to keep is usually determined by how much of the data variance you want to keep  </li></ul></li></ul></li></ul><h1>Chapter 9: Unsupervised Learning Techniques</h1><ul><li>A relatively less developed area of ML</li><li>Clustering<ul><li>K-Means<ul><li>Finds the center of blobs and the boundary of these blobs</li><li>It can sometimes fall into local-optimal</li><li>Techniques to overcome this include put the approximate centroid&#x27;s location, or run it several times and pick the best performing one, choose centroids far away from easy other</li><li>Choosing the best number of cluster can be done empirically with the rule of elbows on a chart between the number of clusters and inertia</li><li>Or precisely with silhouette score<ul><li>mean of silhouette coefficient for all clusters</li><li>calculated by $\frac{(b-a)}{max(a, b)}$</li><li>where $a$ is the mean distance to all other distances in the same cluster (mean intra-cluster distance)</li><li>and $b$ is the mean nearest cluster distance</li><li>it can value from -1 to 1 and -1 means you are risking mis-clustering and 0 then it is close to a cluster boundary and 1 is good</li></ul></li><li>downsides of k-means is that it doesn&#x27;t deal well with non-spherical data which means that we should always scale the input features to ensure this</li><li>can be used as a preprocessing step for supervised, unsupervised learning</li></ul></li><li>DBSCAN<ul><li>The algorithm is as follows<ul><li>identify the instance&#x27;s $\epsilon$ neighborhood by taking each instance and count how many instances are located within a small distance</li><li>if it has some number of samples it is considered a core instance</li><li>all instances in the neighborhood of a core instance belong to the same cluster</li></ul></li></ul></li></ul></li><li>Anomaly Detection<ul><li>Gaussian Mixtures<ul><li>Can also do density estimation, and clustering</li><li>A probabilistic model that assumes that the instances were generated from a mixture of several Gaussian distributions</li></ul></li></ul></li><li>==Given a statistical model with some parameters $\theta$, the world &quot;probability&quot; describes how plausible a future outcome $x$ is, while the world &quot;likelihood&quot; is used to describe how plausible a set of parameter values $\theta$ are, after the outcome $x$ is known==</li><li>Density Estimation</li></ul><h1>Chapter 10: Introduction to Artificial Neural Networks with Keras</h1><ul><li>ANNs are the core of Deep Learning</li><li>The <strong>artificial neuron</strong> first proposed by Warren McCulloch and Walter Pitts has one ore more binary inputs and one binary output<ul><li>The artificial neuron activates its output when more than a certain number of inputs are active</li></ul></li><li>The <strong>perceptron</strong> was invented by Frank Rosenblatt in 1957 and it is a single layer of slightly modified artificial neuron called <strong>threshold logic unit (TLU)</strong><ul><li>The TLU has a threshold function and takes numerical inputs and outputs numerical output</li><li>The numerical inputs are associated with a weight and the threshold logic unit computes the total sum and applies a step function to see if the sum activates the output</li><li>It is connected to all the inputs (when all the neurons in a layer is connected to all the neurons in the previous layer it is called a <strong>dense layer</strong>)</li><li>The input neurons form the <strong>input layer</strong></li><li>The TLUs form the <strong>output layer</strong></li><li>This is trained with Hebb&#x27;s rule - &quot;cells that fire together, wire together&quot;</li><li>Very similar to stochastic gradient descent as the weights are trained based on the residuals of the outputs</li></ul></li><li>Multiple-layer perceptron (MLP) was invented to tackle XOR problem<ul><li>There is one ore more layer of TLUs between the input and output layer which is called the <strong>hidden layer</strong> <ul><li>This advanced artificial neural networks to <strong>deep neural networks</strong></li></ul></li><li>To train MLP, a groundbreaking paper in 1987 proposed the method <strong>backpropagation training</strong></li><li>It consists of a forward pass which saves the intermediate results of each layer (including the hidden ones)</li><li>Then measures the output error</li><li>Then computes how much each layer contributed to the error through chain rule which is called the backwards pass</li><li>Then using gradient descent to tweak all the connection weights using the error gradient computed</li><li>For the backpropagation training to work, the step function in the MLP neurons are changed to logistic function to get the error gradient<ul><li>It can also work with other activation functions</li></ul></li><li>It is also important to initialize the weights of the neurons randomly</li></ul></li><li>Regression MLP<ul><li>Changing the output neuron to use something other than an activation function to get a numerical output</li><li>Use ReLU or softplus to get positive only numerical outputs</li></ul></li><li>Classification MLP<ul><li>Softmax can be used as the output function</li></ul></li></ul><h1>Chapter 11: Training Deep Neural Networks</h1><ul><li>Deeper neural networks with 10+ hidden layers are used to train image recognition</li><li>The increased layers, neurons and connectors introduces new problems<ul><li>Vanishing gradient problem (exploding gradient problem) which makes the lower layers hard to train</li><li>Requires large amounts of training data</li><li>Long training times</li><li>Risk of overfitting</li></ul></li><li>Vanishing gradient problem<ul><li>Logistic activation function makes the gradient saturate as the values approach the two extremes </li><li></li></ul></li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/slip-box/reference-notes/Hands On Machine Learning.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/slip-box/reference-notes/HTTP Response Codes"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">HTTP Response Codes</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/slip-box/reference-notes/Hike the West Coast Trail"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Hike the West Coast Trail</div></a></nav></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2024 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.e81c3511.js"></script>
<script src="/assets/js/main.11de2009.js"></script>
</body>
</html>