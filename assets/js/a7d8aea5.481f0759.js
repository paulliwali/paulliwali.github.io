"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[52787],{28453:(e,i,t)=>{t.d(i,{R:()=>l,x:()=>a});var n=t(96540);const o={},s=n.createContext(o);function l(e){const i=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),n.createElement(s.Provider,{value:i},e.children)}},70876:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>r,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"slip-box/reference-notes/log-likelihood","title":"log-likelihood","description":"- To understand this concept, first we need to explain maximum likelihood estimation","source":"@site/docs/slip-box/reference-notes/log-likelihood.md","sourceDirName":"slip-box/reference-notes","slug":"/slip-box/reference-notes/log-likelihood","permalink":"/docs/slip-box/reference-notes/log-likelihood","draft":false,"unlisted":false,"editUrl":"https://github.com/paulliwali/paulliwali.github.io/tree/main/docs/docs/slip-box/reference-notes/log-likelihood.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"learning curves","permalink":"/docs/slip-box/reference-notes/learning curves"},"next":{"title":"meta-cognition","permalink":"/docs/slip-box/reference-notes/meta-cognition"}}');var o=t(74848),s=t(28453);const l={},a=void 0,r={},d=[];function c(e){const i={a:"a",li:"li",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"To understand this concept, first we need to explain maximum likelihood estimation"}),"\n",(0,o.jsx)(i.li,{children:"==Maximum likelihood estimation is a method that determines values for the parameter of a model. The parameter values are found such that they maximize the likelihood that the process described by the model produced the data that was actually observed=="}),"\n",(0,o.jsxs)(i.li,{children:["For a set of data generated independently, the total probability of observations all the data (joint probability distribution of all observed data) is just the multiplication of each point","\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Assuming we guess/domain knowledge on the distribution, the probability of a single point can be known (i.e. Gaussian (normal) distribution has its own function)"}),"\n",(0,o.jsx)(i.li,{children:"To maximize the joint probability distribution, one differentiates this function and set it to 0"}),"\n",(0,o.jsx)(i.li,{children:"**To make the computation easier, it is common to take the natural logarithm of the function **"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(i.li,{children:["Likelihood vs probability","\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Likelihood is asking what are the values of the parameters given we\u2019ve observed some data"}),"\n",(0,o.jsx)(i.li,{children:"Probability is asking what are the values of the data given the parameters"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(i.li,{children:["When is least square estimation the same as maximum likelihood estimation?","\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"When the distribution is Gaussian, then they are equivalent"}),"\n",(0,o.jsx)(i.li,{children:"Because the maximum probability is found when data points get closer to the mean, and that\u2019s equivalent to minimizing the distance between data points and the mean value"}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsxs)(i.strong,{children:["More accurately, they are equivalent under the following ",(0,o.jsx)(i.a,{href:"https://bookdown.org/egarpor/PM-UC3M/app-ext-mle.html",children:"assumptions"})," of the model"]}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Linearity"}),"\n",(0,o.jsx)(i.li,{children:"Homoscedasticity"}),"\n",(0,o.jsx)(i.li,{children:"Normality"}),"\n",(0,o.jsx)(i.li,{children:"Independence of errors"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})}function h(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,o.jsx)(i,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);