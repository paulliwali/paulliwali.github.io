"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[74727],{13901:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>a,toc:()=>l});var t=s(85893),i=s(11151);const o={source:["https://towardsdatascience.com/chasing-statistical-ghosts-in-experimentation-3f393323a1c1"],author:["Colin McFarland"],tags:["statistics","machine-learning"]},r="\ud83d\udcf0 Summary (use your own words)",a={id:"slip-box/reference-notes/Chasing Statistical Ghosts",title:"\ud83d\udcf0 Summary (use your own words)",description:"First ghost - its either significant or noise",source:"@site/docs/slip-box/reference-notes/Chasing Statistical Ghosts.md",sourceDirName:"slip-box/reference-notes",slug:"/slip-box/reference-notes/Chasing Statistical Ghosts",permalink:"/docs/slip-box/reference-notes/Chasing Statistical Ghosts",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/slip-box/reference-notes/Chasing Statistical Ghosts.md",tags:[{label:"statistics",permalink:"/docs/tags/statistics"},{label:"machine-learning",permalink:"/docs/tags/machine-learning"}],version:"current",frontMatter:{source:["https://towardsdatascience.com/chasing-statistical-ghosts-in-experimentation-3f393323a1c1"],author:["Colin McFarland"],tags:["statistics","machine-learning"]},sidebar:"tutorialSidebar",previous:{title:"Cars and Second Order Consequences",permalink:"/docs/slip-box/reference-notes/Cars and Second Order Consequences"},next:{title:"ChatGPT to help me program an app",permalink:"/docs/slip-box/reference-notes/ChatGPT to help me program an app"}},c={},l=[];function h(e){const n={h1:"h1",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"-summary-use-your-own-words",children:"\ud83d\udcf0 Summary (use your own words)"}),"\n",(0,t.jsx)(n.h1,{id:"\ufe0f-notes",children:"\u270d\ufe0f Notes"}),"\n",(0,t.jsx)(n.p,{children:"First ghost - its either significant or noise"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:['p value tries to answer the question - "what is the likelihood that the observed differences due to the null hypothesis?"',"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'There is no such thing as "the test is nearly significant" or "work towards significance"'}),"\n",(0,t.jsx)(n.li,{children:"There is only significant or uncertain"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Second ghost - the fallacy of session based metrics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If there are users creating multiple sessions, then it is difficult to assert the required assumption of all sessions are independent"}),"\n",(0,t.jsxs)(n.li,{children:["This happens when you are measuring a rate metric which is defined by something other than what you randomized on, for example:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"click through rate (total clicks / total impression) will be skewed if you are randomizing on users"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Third ghost - multiple comparisons"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The more comparisons you make the hgiher your chances of seeing a false positive"}),"\n",(0,t.jsxs)(n.li,{children:["The standard practice of 95% confidence level means that we expect a false positive rate of 5% on a ",(0,t.jsx)(n.strong,{children:"single metric"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"So, as soon as you look at more than one metric you increase the chance"}),"\n",(0,t.jsx)(n.li,{children:"So for a AA test, you would expect an increase in at least one false positive in any metric with an increase in the metrics you are tracking"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["This also applies when testing multiple different treatments and also ",(0,t.jsx)(n.strong,{children:"applies when you break down the results into segments"})]}),"\n",(0,t.jsxs)(n.li,{children:["To correct for this","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"You can adjust the significance threshold with Bonferroni correction"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Fourth ghost - Peeking"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For any test, there is a chance of false positives (seeing a significant result randomly when there isn't). So if we peeked ",(0,t.jsx)(n.strong,{children:"and took action to stop the test"})," we would inflate our results artificially"]}),"\n",(0,t.jsx)(n.li,{children:"The AB testing statistics are only valid when you make one comparison only - they are based on the assumption that you will only make an inference using a snapshot of data at one particular, predetermined, point in time - peeking invalidates that"}),"\n",(0,t.jsxs)(n.li,{children:["To avoid this","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"peeking safely by not actioning"}),"\n",(0,t.jsx)(n.li,{children:"Use sequential hypothesis testing which doesn't require a fixed sample size or predetermined run time"}),"\n",(0,t.jsx)(n.li,{children:"Bayesian methods to not come to the wrong conclusion - refer to [[Is Bayesian AB testing immune to peeking]]"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>a,a:()=>r});var t=s(67294);const i={},o=t.createContext(i);function r(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);