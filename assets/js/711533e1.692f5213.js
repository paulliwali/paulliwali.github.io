"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[20117],{28453:(e,t,a)=>{a.d(t,{R:()=>o,x:()=>r});var n=a(96540);const i={},s=n.createContext(i);function o(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),n.createElement(s.Provider,{value:t},e.children)}},32006:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>o,metadata:()=>n,toc:()=>h});const n=JSON.parse('{"id":"slip-box/reference-notes/Algorithms to live by","title":"\ud83d\udcd6 Short Summary (1 takeaway)","description":"- Applying some crucial algorithms developed for computer science and math can be applied to real life. These span use cases like decision making, sorting, determining the best, storing information, making guesses, optimize things, think heuristically, how modern technology works","source":"@site/docs/slip-box/reference-notes/Algorithms to live by.md","sourceDirName":"slip-box/reference-notes","slug":"/slip-box/reference-notes/Algorithms to live by","permalink":"/docs/slip-box/reference-notes/Algorithms to live by","draft":false,"unlisted":false,"editUrl":"https://github.com/paulliwali/paulliwali.github.io/tree/main/docs/docs/slip-box/reference-notes/Algorithms to live by.md","tags":[{"inline":true,"label":"non-fiction","permalink":"/docs/tags/non-fiction"}],"version":"current","frontMatter":{"author":["Brian Christian and Tom Griffiths"],"tags":["non-fiction"]},"sidebar":"tutorialSidebar","previous":{"title":"Aggregation Theory","permalink":"/docs/slip-box/reference-notes/Aggregation Theory"},"next":{"title":"Alta Via 1 of the Dolomites","permalink":"/docs/slip-box/reference-notes/Alta Via 1 of the Dolomites"}}');var i=a(74848),s=a(28453);const o={author:["Brian Christian and Tom Griffiths"],tags:["non-fiction"]},r="\ud83d\udcd6 Short Summary (1 takeaway)",l={},h=[];function m(e){const t={annotation:"annotation",blockquote:"blockquote",h1:"h1",header:"header",li:"li",math:"math",mi:"mi",mn:"mn",mrow:"mrow",p:"p",semantics:"semantics",span:"span",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"-short-summary-1-takeaway",children:"\ud83d\udcd6 Short Summary (1 takeaway)"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Applying some crucial algorithms developed for computer science and math can be applied to real life. These span use cases like decision making, sorting, determining the best, storing information, making guesses, optimize things, think heuristically, how modern technology works"}),"\n"]}),"\n",(0,i.jsx)(t.h1,{id:"-why-i-am-reading-this-book",children:"\ud83e\uddd0 Why I am reading this book"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Part of [[8. \u2615\ufe0f Finer Things Book Club]]"}),"\n"]}),"\n",(0,i.jsx)(t.h1,{id:"-great-quotes",children:"\ud83d\ude4a Great quotes"}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:["Over the past decade or two, behavioral economics has told a very particular story about human beings: that we are irrational and error-prone, owing in large part to the buggy, idiosyncratic hardware of the brain.\nLook-Then-Leap Rule: You set a predetermined amount of time for \u201clooking\u201d\u2014that is, exploring your options, gathering data\u2014in which you categorically don\u2019t choose anyone, no matter how impressive. After that point, you enter the \u201cleap\u201d\nThe math shows that you should always keep playing. But if you follow this strategy, you will eventually lose everything. Some problems are better avoided than solved.\nSpend the afternoon. You can\u2019t take it with you.\nWhen balancing favorite experiences and new ones, nothing matters as much as the interval over which we plan to enjoy them.\nThe old adage tells us that \u201cthe grass is always greener on the other side of the fence,\u201d but the math tells us why: the unknown has a chance of being better, even if we actually expect it to be no different, or if it\u2019s just as likely to be worse.\nFollowing the advice of these algorithms, you should be excited to meet new people and try new things\u2014to assume the best about them, in the absence of evidence to the contrary.\nData scientist Jeff Hammerbacher, former manager of the Data group at Facebook, once told Bloomberg Businessweek that \u201cthe best minds of my generation are thinking about how to make people click ads.\u201d\nIn general, it seems that people tend to over-explore\u2014to favor the new disproportionately over the best.\nSorting something that you will never search is a complete waste; searching something you never sorted is merely inefficient.\nIronically, in Single Elimination no tournament structure is actually necessary at all. Any 63 games will yield a single undefeated champion. For instance, you could simply have a single \u201cking of the hill\u201d team take on challengers one by one until it is dethroned, at which point whoever defeated it takes over its spot and continues.\nAs Trick points out, sports leagues aren\u2019t concerned with determining the rankings as quickly and expeditiously as possible. Instead, sports calendars are explicitly designed to maintain tension throughout the season, something that has rarely been a concern of sorting theory.\nIn the practical use of our intellect, forgetting is as important a function as remembering.\nLRU consistently performed the closest to clairvoyance.\n\u201ctemporal locality\u201d: if a program has called for a particular piece of information once, it\u2019s likely to do so again in the near future.\nUnless we have good reason to think otherwise, it seems that our best guide to the future is a mirror image of the past. The nearest thing to clairvoyance is to assume that history repeats itself\u2014backward.\nThe key idea behind Anderson\u2019s new account of human memory is that the problem might be not one of storage, but of organization. According to his theory, the mind has essentially infinite capacity for memories, but we have only a finite amount of time in which to search for them.\n\u201cIf you\u2019re flammable and have legs, you are never blocking a fire exit.\u201d\n\u201cThe TeX Tuneup of 2014,\u201d in which he fixed all of the bugs that had been reported in his TeX typesetting software over the previous six years. His report ends with the cheery sign-off \u201cStay tuned for The TeX Tuneup of 2021!\u201d\nAlert me only once every ten minutes, say; then tell me everything.\nOur days are full of \u201csmall data.\u201d\nPerhaps we had already intuited as much, but Bayes\u2019s logic offers us the ability to quantify that intuition.\nIn fact, for any possible drawing of w winning tickets in n attempts, the expectation is simply the number of wins plus one, divided by the number of attempts plus two: (w+1)\u2044(n+2). This incredibly simple scheme for estimating probabilities is known as Laplace\u2019s Law, and it is easy to apply in any situation where you need to assess the chances of an event based on its history. And the beauty of Laplace\u2019s Law is that it works equally well whether we have a single data point or millions of them.\nThe mathematical formula that describes this relationship, tying together our previously held ideas and the evidence before our eyes, has come to be known\u2014ironically, as the real heavy lifting was done by Laplace\u2014as Bayes\u2019s Rule.\nThe Erlang distribution gives us a third kind of prediction rule, the Additive Rule: always predict that things will go on just a constant amount longer.\nThese three very different patterns of optimal prediction\u2014the Multiplicative, Average, and Additive Rules\u2014all result directly from applying Bayes\u2019s Rule to the power-law, normal, and Erlang distributions, respectively.\nIn other words, the ability to resist temptation may be, at least in part, a matter of expectations rather than willpower.\nFailing the marshmallow test\u2014and being less successful in later life\u2014may not be about lacking willpower. It could be a result of believing that adults are not dependable: that they can\u2019t be trusted to keep their word, that they disappear for intervals of arbitrary length. Learning self-control is important, but it\u2019s equally important to grow up in an environment where adults are consistently present and trustworthy.\nyou want to be a good intuitive Bayesian\u2014if you want to naturally make good predictions, without having to think about what kind of prediction rule is appropriate\u2014you need to protect your priors.\nThe lesson is this: it is indeed true that including more factors in a model will always, by definition, make it a better fit for the data we have already. But a better fit for the available data does not necessarily mean a better prediction.\nBusiness plans get compressed to an elevator pitch; life advice becomes proverbial wisdom only if it is sufficiently concise and catchy. And anything that needs to be remembered has to pass through the inherent Lasso of memory.\nWhen we start designing something, we sketch out ideas with a big, thick Sharpie marker, instead of a ball-point pen. Why? Pen points are too fine. They\u2019re too high-resolution. They encourage you to worry about things that you shouldn\u2019t worry about yet, like perfecting the shading or whether to use a dotted or dashed line.\nThe first, Constraint Relaxation, simply removes some constraints altogether and makes progress on a looser form of the problem before coming back to reality.\nThe second, Continuous Relaxation, turns discrete or binary choices into continua: when deciding between iced tea and lemonade, first imagine a 50\u201350 \u201cArnold Palmer\u201d blend and then round it up or down.\nThe third, Lagrangian Relaxation, turns impossibilities into mere penalties, teaching the art of bending the rules\nMetropolis named this approach\u2014replacing exhaustive probability calculations with sample simulations\u2014the Monte Carlo Method,\nAggregate statistics, on the other hand, are the reverse: comprehensive but thin.\nAs Harvard\u2019s Michael Mitzenmacher puts it, \u201cWhat we\u2019re going to do is come up with an answer which saves you in time and space and trades off this third dimension: error probability.\u201d\nThe river meanders because it can\u2019t think.\nProtocol is how we get on the same page; in fact, the word is rooted in the Greek protokollon, \u201cfirst glue,\u201d which referred to the outer page attached to a book or manuscript.\nThe technology that ate circuit switching\u2019s lunch would become known as packet switching.\nIn packet switching, on the other hand, the proliferation of paths in a growing network becomes a virtue: there are now that many more ways for data to flow, so the reliability of the network increases exponentially with its size.\nThe way that ACKs work is both simple and clever. Behind the scenes of the triple handshake, each machine provides the other with a kind of serial number\u2014and it\u2019s understood that every packet sent after that will increment those serial numbers by one each time, like checks in a checkbook.\nReal-time voice communications, such as Skype, typically do not use TCP, if you lose a packet, you just say, \u2018Say that again, I missed something.\u2019\u201d\nIn one of the seminal results in game theory, the mathematician John Nash proved in 1951 that every two-player game has at least one equilibrium.\nIn a game-theory context, knowing that an equilibrium exists doesn\u2019t actually tell us what it is\u2014or how to get there.\nIn fact, this makes defection not merely the equilibrium strategy but what\u2019s known as a dominant strategy. A dominant strategy avoids recursion altogether, by being the best response to all of your opponent\u2019s possible strategies\u2014so you don\u2019t even need to trouble yourself getting inside their head at all. A dominant strategy is a powerful thing.\nThe price of anarchy measures the gap between cooperation (a centrally designed or coordinated solution) and competition (where each participant is independently trying to maximize the outcome for themselves).\nWhenever you find yourself on the side of the majority, it is time to pause and reflect.\nHere game theory offers a sobering perspective: catastrophes like this can happen even when no one\u2019s at fault.\nDutch auctions are more prevalent than they might initially seem. A store marking down its unsold items, and landlords listing apartments at the highest price they think the market will bear, both share its basic quality: the seller is likely to begin optimistically and nudge the price down until a buyer is found.\nIn an English auction, bidders alternate raising the price until all but one of them drop out. This seems to offer something closer to what we want: here, if you value an item at ",(0,i.jsxs)(t.span,{className:"katex",children:[(0,i.jsx)(t.span,{className:"katex-mathml",children:(0,i.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(t.semantics,{children:[(0,i.jsxs)(t.mrow,{children:[(0,i.jsx)(t.mn,{children:"25"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"n"}),(0,i.jsx)(t.mi,{children:"d"}),(0,i.jsx)(t.mi,{children:"I"}),(0,i.jsx)(t.mi,{children:"v"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"l"}),(0,i.jsx)(t.mi,{children:"u"}),(0,i.jsx)(t.mi,{children:"e"}),(0,i.jsx)(t.mi,{children:"i"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"t"})]}),(0,i.jsx)(t.annotation,{encoding:"application/x-tex",children:"25 and I value it at "})]})})}),(0,i.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(t.span,{className:"base",children:[(0,i.jsx)(t.span,{className:"strut",style:{height:"0.6944em"}}),(0,i.jsx)(t.span,{className:"mord",children:"25"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"an"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.07847em"},children:"I"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"v"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"a"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"l"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"u"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"e"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"i"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"a"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"})]})})]}),"10, you\u2019ll win it for just over ",(0,i.jsxs)(t.span,{className:"katex",children:[(0,i.jsx)(t.span,{className:"katex-mathml",children:(0,i.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(t.semantics,{children:[(0,i.jsxs)(t.mrow,{children:[(0,i.jsx)(t.mn,{children:"10"}),(0,i.jsx)(t.mi,{children:"w"}),(0,i.jsx)(t.mi,{children:"i"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"h"}),(0,i.jsx)(t.mi,{children:"o"}),(0,i.jsx)(t.mi,{children:"u"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"e"}),(0,i.jsx)(t.mi,{children:"i"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"h"}),(0,i.jsx)(t.mi,{children:"e"}),(0,i.jsx)(t.mi,{children:"r"}),(0,i.jsx)(t.mi,{children:"h"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"v"}),(0,i.jsx)(t.mi,{children:"i"}),(0,i.jsx)(t.mi,{children:"n"}),(0,i.jsx)(t.mi,{children:"g"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"o"}),(0,i.jsx)(t.mi,{children:"g"}),(0,i.jsx)(t.mi,{children:"o"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"l"}),(0,i.jsx)(t.mi,{children:"l"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"h"}),(0,i.jsx)(t.mi,{children:"e"}),(0,i.jsx)(t.mi,{children:"w"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"y"}),(0,i.jsx)(t.mi,{children:"t"}),(0,i.jsx)(t.mi,{children:"o"})]}),(0,i.jsx)(t.annotation,{encoding:"application/x-tex",children:"10 without either having to go all the way to "})]})})}),(0,i.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(t.span,{className:"base",children:[(0,i.jsx)(t.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(t.span,{className:"mord",children:"10"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"i"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"h"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"o"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"u"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"e"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"i"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"h"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"er"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"ha"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"v"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"in"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"o"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"o"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"a"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"llt"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"h"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"e"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"a"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"o"})]})})]}),"25 or disappearing down the strategic rabbit hole.\nHowever, in a Vickrey auction, the winner ends up paying not the amount of their own bid, but that of the second-place bidder. That is to say, if you bid ",(0,i.jsxs)(t.span,{className:"katex",children:[(0,i.jsx)(t.span,{className:"katex-mathml",children:(0,i.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(t.semantics,{children:[(0,i.jsxs)(t.mrow,{children:[(0,i.jsx)(t.mn,{children:"25"}),(0,i.jsx)(t.mi,{children:"a"}),(0,i.jsx)(t.mi,{children:"n"}),(0,i.jsx)(t.mi,{children:"d"}),(0,i.jsx)(t.mi,{children:"I"}),(0,i.jsx)(t.mi,{children:"b"}),(0,i.jsx)(t.mi,{children:"i"}),(0,i.jsx)(t.mi,{children:"d"})]}),(0,i.jsx)(t.annotation,{encoding:"application/x-tex",children:"25 and I bid "})]})})}),(0,i.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(t.span,{className:"base",children:[(0,i.jsx)(t.span,{className:"strut",style:{height:"0.6944em"}}),(0,i.jsx)(t.span,{className:"mord",children:"25"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"an"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.07847em"},children:"I"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"bi"}),(0,i.jsx)(t.span,{className:"mord mathnormal",children:"d"})]})})]}),"10, you win the item at my price: you only have to pay $10.\nIn a Vickrey auction, on the other hand, honesty is the dominant strategy. This is the mechanism designer\u2019s holy grail. You do not need to strategize or recurse.\nIn a landmark finding called the \u201crevelation principle,\u201d Nobel laureate Roger Myerson proved that any game that requires strategically masking the truth can be transformed into a game that requires nothing but simple honesty.\nThe 37% Rule, the Least Recently Used criterion for handling overflowing caches, and the Upper Confidence Bound as a guide to exploration are all examples of this.\nEven the best strategy sometimes yields bad results\u2014which is why computer scientists take care to distinguish between \u201cprocess\u201d and \u201coutcome.\u201d If you followed the best possible process, then you\u2019ve done all you can, and you shouldn\u2019t blame yourself if things didn\u2019t go your way.\nCall it a kind of computational Stoicism.\nIf you wind up stuck in an intractable scenario, remember that heuristics, approximations, and strategic use of randomness can help you find workable solutions.\nsometimes \u201cgood enough\u201d really is good enough. What\u2019s more, being aware of complexity can help us pick our problems:\nThese aren\u2019t the concessions we make when we can\u2019t be rational. They\u2019re what being rational means."]}),"\n"]}),"\n",(0,i.jsx)(t.h1,{id:"-actionable-item",children:"\u2705 Actionable item"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"[ ]"}),"\n"]}),"\n",(0,i.jsx)(t.h1,{id:"-detailed-summary",children:"\ud83d\uddc2 Detailed Summary"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{}),"\n"]})]})}function c(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}}}]);