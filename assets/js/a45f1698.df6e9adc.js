"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[16667],{2403:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"slip-box/reference-notes/Chasing Statistical Ghosts","title":"\ud83d\udcf0 Summary (use your own words)","description":"First ghost - its either significant or noise","source":"@site/docs/slip-box/reference-notes/Chasing Statistical Ghosts.md","sourceDirName":"slip-box/reference-notes","slug":"/slip-box/reference-notes/Chasing Statistical Ghosts","permalink":"/docs/slip-box/reference-notes/Chasing Statistical Ghosts","draft":false,"unlisted":false,"editUrl":"https://github.com/paulliwali/paulliwali.github.io/tree/main/docs/docs/slip-box/reference-notes/Chasing Statistical Ghosts.md","tags":[{"inline":true,"label":"statistics","permalink":"/docs/tags/statistics"},{"inline":true,"label":"machine-learning","permalink":"/docs/tags/machine-learning"}],"version":"current","frontMatter":{"source":["https://towardsdatascience.com/chasing-statistical-ghosts-in-experimentation-3f393323a1c1"],"author":["Colin McFarland"],"tags":["statistics","machine-learning"]},"sidebar":"tutorialSidebar","previous":{"title":"Cars and Second Order Consequences","permalink":"/docs/slip-box/reference-notes/Cars and Second Order Consequences"},"next":{"title":"ChatGPT to help me program an app","permalink":"/docs/slip-box/reference-notes/ChatGPT to help me program an app"}}');var t=s(74848),r=s(28453);const o={source:["https://towardsdatascience.com/chasing-statistical-ghosts-in-experimentation-3f393323a1c1"],author:["Colin McFarland"],tags:["statistics","machine-learning"]},a="\ud83d\udcf0 Summary (use your own words)",l={},c=[];function h(e){const n={h1:"h1",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"-summary-use-your-own-words",children:"\ud83d\udcf0 Summary (use your own words)"})}),"\n",(0,t.jsx)(n.h1,{id:"\ufe0f-notes",children:"\u270d\ufe0f Notes"}),"\n",(0,t.jsx)(n.p,{children:"First ghost - its either significant or noise"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:['p value tries to answer the question - "what is the likelihood that the observed differences due to the null hypothesis?"',"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'There is no such thing as "the test is nearly significant" or "work towards significance"'}),"\n",(0,t.jsx)(n.li,{children:"There is only significant or uncertain"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Second ghost - the fallacy of session based metrics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If there are users creating multiple sessions, then it is difficult to assert the required assumption of all sessions are independent"}),"\n",(0,t.jsxs)(n.li,{children:["This happens when you are measuring a rate metric which is defined by something other than what you randomized on, for example:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"click through rate (total clicks / total impression) will be skewed if you are randomizing on users"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Third ghost - multiple comparisons"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The more comparisons you make the hgiher your chances of seeing a false positive"}),"\n",(0,t.jsxs)(n.li,{children:["The standard practice of 95% confidence level means that we expect a false positive rate of 5% on a ",(0,t.jsx)(n.strong,{children:"single metric"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"So, as soon as you look at more than one metric you increase the chance"}),"\n",(0,t.jsx)(n.li,{children:"So for a AA test, you would expect an increase in at least one false positive in any metric with an increase in the metrics you are tracking"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["This also applies when testing multiple different treatments and also ",(0,t.jsx)(n.strong,{children:"applies when you break down the results into segments"})]}),"\n",(0,t.jsxs)(n.li,{children:["To correct for this","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"You can adjust the significance threshold with Bonferroni correction"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Fourth ghost - Peeking"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For any test, there is a chance of false positives (seeing a significant result randomly when there isn't). So if we peeked ",(0,t.jsx)(n.strong,{children:"and took action to stop the test"})," we would inflate our results artificially"]}),"\n",(0,t.jsx)(n.li,{children:"The AB testing statistics are only valid when you make one comparison only - they are based on the assumption that you will only make an inference using a snapshot of data at one particular, predetermined, point in time - peeking invalidates that"}),"\n",(0,t.jsxs)(n.li,{children:["To avoid this","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"peeking safely by not actioning"}),"\n",(0,t.jsx)(n.li,{children:"Use sequential hypothesis testing which doesn't require a fixed sample size or predetermined run time"}),"\n",(0,t.jsx)(n.li,{children:"Bayesian methods to not come to the wrong conclusion - refer to [[Is Bayesian AB testing immune to peeking]]"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>a});var i=s(96540);const t={},r=i.createContext(t);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);