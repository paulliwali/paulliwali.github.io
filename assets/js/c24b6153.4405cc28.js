"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[26105],{79228:e=>{e.exports=JSON.parse('{"label":"machine-learning","permalink":"/docs/tags/machine-learning","allTagsPath":"/docs/tags","count":7,"items":[{"id":"slip-box/reference-notes/Chasing Statistical Ghosts","title":"\ud83d\udcf0 Summary (use your own words)","description":"First ghost - its either significant or noise","permalink":"/docs/slip-box/reference-notes/Chasing Statistical Ghosts"},{"id":"slip-box/reference-notes/GPT in SQL","title":"\ud83d\udcf0 Summary (use your own words)","description":"Explains GPT with a SQL demo","permalink":"/docs/slip-box/reference-notes/GPT in SQL"},{"id":"slip-box/reference-notes/Is Bayesian AB testing immune to peeking","title":"\ud83d\udcf0 Summary (use your own words)","description":"The Bayesian AB testing approach does mitigate the problem of peeking but it still increases the Type I error which is not the promise that the Bayesian approach promises. Conversely, because the frequentist approach is promising a Type I error rate in the form of p-value testing, it is explicitly breaking that promise if we peeked and took action on the experiments.","permalink":"/docs/slip-box/reference-notes/Is Bayesian AB testing immune to peeking"},{"id":"slip-box/reference-notes/MLOps is mostly data engineering","title":"\ud83d\udcf0 Summary (use your own words)","description":"There is an infrastructure need to run and operate machine learning in production. The category of jobs related to this is labelled as MLOps or \\"Machine Learning Operations\\", but it is becoming apparent that there is a lot of overlap with the traditional data engineering roles.","permalink":"/docs/slip-box/reference-notes/MLOps is mostly data engineering"},{"id":"slip-box/reference-notes/Data Science Cheat Sheet","title":"Data Science Cheat Sheet","description":"Inspired by this https://python-data-science.readthedocs.io/en/latest/_images/architecture.png","permalink":"/docs/slip-box/reference-notes/Data Science Cheat Sheet"},{"id":"slip-box/reference-notes/k-fold cross validation","title":"k-fold cross validation","description":"- A way to evaluate model\'s design on limited data set","permalink":"/docs/slip-box/reference-notes/k-fold cross validation"},{"id":"slip-box/reference-notes/Mixture of Models","title":"What is it?","description":"A way to subdivide a giant neural network into sub-networks which can be expertly trained on one aspect of the problem and then sparsely combined back together for each task.","permalink":"/docs/slip-box/reference-notes/Mixture of Models"}],"unlisted":false}')}}]);