"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[56327],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>f});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),u=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},p=function(e){var t=u(e.components);return n.createElement(s.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=u(r),d=a,f=c["".concat(s,".").concat(d)]||c[d]||m[d]||i;return r?n.createElement(f,o(o({ref:t},p),{},{components:r})):n.createElement(f,o({ref:t},p))}));function f(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=r.length,o=new Array(i);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[c]="string"==typeof e?e:a,o[1]=l;for(var u=2;u<i;u++)o[u]=r[u];return n.createElement.apply(null,o)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},86985:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>l,toc:()=>u});var n=r(87462),a=(r(67294),r(3905));const i={},o=void 0,l={unversionedId:"roam/Linear regression model",id:"roam/Linear regression model",title:"Linear regression model",description:"- Try to predict a continuous target variable given a set of inputs",source:"@site/docs/roam/Linear regression model.md",sourceDirName:"roam",slug:"/roam/Linear regression model",permalink:"/docs/roam/Linear regression model",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/roam/Linear regression model.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Learn About Investing",permalink:"/docs/roam/Learn About Investing"},next:{title:"Loss Aversion Theory",permalink:"/docs/roam/Loss Aversion Theory"}},s={},u=[],p={toc:u};function c(e){let{components:t,...r}=e;return(0,a.kt)("wrapper",(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Try to predict a continuous target variable given a set of inputs")),(0,a.kt)("li",{parentName:"ul"},"Makes prediction on the weighted sum of input features and bias term (intercept)",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"$$\\hat{y} = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n$$"),(0,a.kt)("li",{parentName:"ul"},"Vectorized form: $$\\hat{y}=h_{\\Theta}(X)=\\Theta \\cdot X = \\Theta^{T}X$$"))),(0,a.kt)("li",{parentName:"ul"},"[","[normal equation]","] is a closed-form solution to minimize the cost function of a linear regression model."),(0,a.kt)("li",{parentName:"ul"},"Least squares solution",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Assumes the target variable is a linear combination of feature variables"),(0,a.kt)("li",{parentName:"ul"},"Assumes Y is distributed normally, X^T*X is invertible and the expected value of epsilon is zero with constant variance"))),(0,a.kt)("li",{parentName:"ul"},"Weighted least squares",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To combat heteroscedasticity in the errors"),(0,a.kt)("li",{parentName:"ul"},"Determine the weights requires work"))),(0,a.kt)("li",{parentName:"ul"},"Overfitting",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"[","[Regularization Techniques]","]",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Adds a penalty term to the loss function that penalize the parameters of the model"))))),(0,a.kt)("li",{parentName:"ul"},"Underfitting",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"[","[Kernel Regression]","]",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"A density function to map input variables to a higher dimension"))),(0,a.kt)("li",{parentName:"ul"},"[","[Support Vector Machines]","]",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Support vectors are the margins around decision boundaries")))))))}c.isMDXComponent=!0}}]);